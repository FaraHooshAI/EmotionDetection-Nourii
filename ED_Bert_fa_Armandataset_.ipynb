{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIbEl3/iGTwQ3nkmslsNn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryamNourii/EmotionDetection/blob/Define_Train_Model/ED_Bert_fa_Armandataset_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz11xTXFw1oA",
        "outputId": "f0071420-3b3c-4022-bfed-b2e4f5c5ab87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoConfig, AutoTokenizer, TFAutoModel,TFBertForSequenceClassification\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from transformers import TFBertModel, BertTokenizerFast, BertConfig\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import TruncatedNormal"
      ],
      "metadata": {
        "id": "PepcLxebw5HK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "# MODEL_NAME_OR_PATH = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "w_mUV3lVxK7v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/CleanData_arman.csv', sep=',')"
      ],
      "metadata": {
        "id": "fXjqVgQMxQQp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['text'].isnull()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "i4MZjDYexTFh",
        "outputId": "2c6cefb6-ad3b-4755-b74d-d44102c70696"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93d4681d-56b1-4180-9c01-0d518f289a47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93d4681d-56b1-4180-9c01-0d518f289a47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93d4681d-56b1-4180-9c01-0d518f289a47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93d4681d-56b1-4180-9c01-0d518f289a47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['target'] = data['label'].map({'SAD':0, 'HATE':1, 'FEAR':2, 'ANGRY':3, 'HAPPY':4, 'SURPRISE':5, 'OTHER':6})\n",
        "data_x = data['text']\n",
        "data_y = data['target']"
      ],
      "metadata": {
        "id": "pxIgZ19ZxU7q"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKLyleReweaU",
        "outputId": "611f519e-618f-4147-e7a6-c48277b365d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "max_length = data_x.apply(lambda x: len(x.split())).max()\n",
        "max_length  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained(MODEL_NAME_OR_PATH, output_hidden_states=False)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = MODEL_NAME_OR_PATH, config = config)\n",
        "transformer_model = TFAutoModel.from_pretrained(MODEL_NAME_OR_PATH, config = config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXj6VHJpxldI",
        "outputId": "1b968a9c-c4ef-44a9-83cd-25a807f17ad8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32')\n",
        "token_ids = Input(shape=(max_length,), name='token_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "bert_model = transformer_model(inputs)[1]\n",
        "pooled_output = Dropout(config.hidden_dropout_prob, name='pooled_output')(bert_model, training=False)\n",
        "\n",
        "emotion = Dense(units=7, activation=\"sigmoid\", kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='emotion')(pooled_output)\n",
        "outputs = emotion\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel')\n",
        "model.layers[1].trainable = False"
      ],
      "metadata": {
        "id": "GWK2s_lGyAxY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZzFmcYjyEpW",
        "outputId": "187c3f1b-e284-4c76-f122-9249deed11f9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"BERT_MultiLabel\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 48)]         0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 48)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  162841344   ['attention_mask[0][0]',         \n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 48,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 768)          0           ['tf_bert_model_2[0][1]']        \n",
            "                                                                                                  \n",
            " emotion (Dense)                (None, 7)            5383        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 162,846,727\n",
            "Trainable params: 162,846,727\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(data_x,data_y,test_size=0.2)\n",
        "train_x,val_x,train_y,val_y = train_test_split(train_x,train_y,test_size=0.1)"
      ],
      "metadata": {
        "id": "flvgTx1w0cxR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = tokenizer(\n",
        "    text = train_x.to_list(),\n",
        "    add_special_tokens = True,\n",
        "    max_length = max_length,\n",
        "    truncation = True,\n",
        "    padding = 'max_length', \n",
        "    return_tensors = 'tf',\n",
        "    return_token_type_ids = True,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "val_token = tokenizer(\n",
        "    text = val_x.to_list(),\n",
        "    add_special_tokens = True,\n",
        "    max_length = max_length,\n",
        "    truncation = True,\n",
        "    padding = 'max_length', \n",
        "    return_tensors = 'tf',\n",
        "    return_token_type_ids = True,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "test_token = tokenizer(\n",
        "    text = test_x.to_list(),\n",
        "    add_special_tokens = True,\n",
        "    max_length = max_length,\n",
        "    truncation = True,\n",
        "    padding = 'max_length', \n",
        "    return_tensors = 'tf',\n",
        "    return_token_type_ids = True,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "SujZ8LPeyRAm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = {'input_ids': train_token['input_ids'], 'attention_mask': train_token['attention_mask'],'token_ids': train_token['token_type_ids']}\n",
        "val = {'input_ids': val_token['input_ids'], 'attention_mask': val_token['attention_mask'],'token_ids': val_token['token_type_ids']}\n",
        "test = {'input_ids': test_token['input_ids'], 'attention_mask': test_token['attention_mask'],'token_ids': test_token['token_type_ids']}"
      ],
      "metadata": {
        "id": "o6-OnfPNyUy8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor = tf.data.Dataset.from_tensor_slices((train, train_y)).shuffle(len(train)).batch(16)\n",
        "val_tensor = tf.data.Dataset.from_tensor_slices((val, val_y)).shuffle(len(val)).batch(16)\n",
        "test_tensor = tf.data.Dataset.from_tensor_slices((test, test_y)).shuffle(len(test)).batch(16)"
      ],
      "metadata": {
        "id": "sSx2A6t5yWe1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5.e-05,\n",
        "    )\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss,\n",
        "    metrics = [metric])\n",
        "\n",
        "\n",
        "log_dir='tb_bert'\n",
        "model_save_path='bert_model.h5'\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
        "                                                save_weights_only=True,\n",
        "                                                monitor='val_loss',mode='min'\n",
        "                                                ,save_best_only=True),\n",
        "                                                tf.keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
        "\n",
        "history = model.fit(train_tensor, \n",
        "                    epochs=4, \n",
        "                    validation_data=val_tensor,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rkanqMVyb7P",
        "outputId": "28e10cea-2170-41ac-811f-58af6e11cc85"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['token_ids'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "293/293 [==============================] - 89s 231ms/step - loss: 1.4035 - accuracy: 0.4795 - val_loss: 1.1754 - val_accuracy: 0.5988\n",
            "Epoch 2/4\n",
            "293/293 [==============================] - 63s 213ms/step - loss: 0.9035 - accuracy: 0.6908 - val_loss: 1.2689 - val_accuracy: 0.5854\n",
            "Epoch 3/4\n",
            "293/293 [==============================] - 63s 213ms/step - loss: 0.5539 - accuracy: 0.8220 - val_loss: 1.3842 - val_accuracy: 0.5758\n",
            "Epoch 4/4\n",
            "293/293 [==============================] - 62s 212ms/step - loss: 0.3589 - accuracy: 0.8889 - val_loss: 1.5866 - val_accuracy: 0.5969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(test_tensor)"
      ],
      "metadata": {
        "id": "JMK4EjSxyeYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a44e1e9-3605-4ff5-b4b9-53f6b2763cf7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/82 [==============================] - 8s 65ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnW8wSREeqDm",
        "outputId": "530a0b88-6976-4336-ce87-19cfeeef1860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.992389  , 0.20858517, 0.22776924, ..., 0.95903873, 0.06093171,\n",
              "        0.03556877],\n",
              "       [0.07805462, 0.9997267 , 0.33255666, ..., 0.10958179, 0.14960788,\n",
              "        0.07282835],\n",
              "       [0.9991611 , 0.49396893, 0.12589207, ..., 0.41559   , 0.10181875,\n",
              "        0.02942073],\n",
              "       ...,\n",
              "       [0.21426617, 0.16826105, 0.09782495, ..., 0.98526716, 0.97582895,\n",
              "        0.03812208],\n",
              "       [0.09479297, 0.99965847, 0.21344616, ..., 0.1591344 , 0.16077018,\n",
              "        0.09186505],\n",
              "       [0.361214  , 0.15158099, 0.11224746, ..., 0.94728696, 0.239922  ,\n",
              "        0.03555888]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}